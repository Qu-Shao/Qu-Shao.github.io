<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="ITNAemUjXaTd1v5hUBGye5IrdyCfz_nS7lgBEtda2">
  <meta name="msvalidate.01" content="86188A2C1964427EB942511DCFE5EB04">
  <meta name="yandex-verification" content="6a2497eda9a46d64">
  <meta name="baidu-site-verification" content="codeva-8LOI8JhMYp">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/green/pace-theme-bounce.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"qushao.top","root":"/","images":"/images","scheme":"Pisces","darkmode":true,"version":"8.19.1","exturl":true,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"buttons","active":"changyan","storage":true,"lazyload":true,"nav":null,"activeClass":"changyan"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="CNN(卷积神经网络)学习笔记，包括卷积神经网络的基础以及CNN典型网络的实现">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN（卷积神经网络）学习笔记">
<meta property="og:url" content="http://qushao.top/2022/04831f11ff.html">
<meta property="og:site_name" content="屈少">
<meta property="og:description" content="CNN(卷积神经网络)学习笔记，包括卷积神经网络的基础以及CNN典型网络的实现">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://qushao.top/images/CNN.png">
<meta property="og:image" content="http://qushao.top/images/LeNet.jpeg">
<meta property="og:image" content="http://qushao.top/images/LeNet_acc.png">
<meta property="og:image" content="http://qushao.top/images/LeNet_loss.png">
<meta property="og:image" content="http://qushao.top/images/LeNet_res.png">
<meta property="og:image" content="http://qushao.top/images/AlexNet.png">
<meta property="og:image" content="http://qushao.top/images/AlexNet_acc.png">
<meta property="og:image" content="http://qushao.top/images/AlexNet_loss.png">
<meta property="og:image" content="http://qushao.top/images/AlexNet_res.png">
<meta property="og:image" content="http://qushao.top/images/VGGNet.png">
<meta property="og:image" content="http://qushao.top/images/VGGNet16_acc.png">
<meta property="og:image" content="http://qushao.top/images/VGGNet16_loss.png">
<meta property="og:image" content="http://qushao.top/images/VGGNet16_res.png">
<meta property="article:published_time" content="2022-04-10T14:00:00.000Z">
<meta property="article:modified_time" content="2022-04-10T14:00:00.000Z">
<meta property="article:author" content="屈少">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="读书笔记">
<meta property="article:tag" content="CNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://qushao.top/images/CNN.png">


<link rel="canonical" href="http://qushao.top/2022/04831f11ff.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://qushao.top/2022/04831f11ff.html","path":"2022/04831f11ff.html","title":"CNN（卷积神经网络）学习笔记"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CNN（卷积神经网络）学习笔记 | 屈少</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WKP2CMZE2V"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-WKP2CMZE2V","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?0ddcc639e41cc35b7f63315fe5f877fe"></script>







  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">屈少</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN-%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"><span class="nav-number">1.</span> <span class="nav-text">CNN(卷积神经网络)学习笔记</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">1.0.1.</span> <span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9B%BE%E7%89%87%E5%8D%B7%E7%A7%AF%E8%BE%93%E5%87%BA%E5%A4%A7%E5%B0%8F%E5%85%AC%E5%BC%8F%EF%BC%9A"><span class="nav-number">1.0.1.0.1.</span> <span class="nav-text">图片卷积输出大小公式：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%8F%82%E6%95%B0%E4%B8%AA%E6%95%B0%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%EF%BC%9A"><span class="nav-number">1.0.1.0.2.</span> <span class="nav-text">卷积层参数个数计算公式：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E6%A1%88%E4%BE%8B"><span class="nav-number">1.0.2.</span> <span class="nav-text">经典案例 </span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#LeNet"><span class="nav-number">1.0.2.0.1.</span> <span class="nav-text">LeNet</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%EF%BC%9A"><span class="nav-number">1.0.2.0.1.1.</span> <span class="nav-text">模型结构：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%90%84%E5%B1%82%E5%8F%82%E6%95%B0%E5%8F%98%E5%8C%96%EF%BC%9A"><span class="nav-number">1.0.2.0.1.2.</span> <span class="nav-text">各层参数变化：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E4%BB%A3%E7%A0%81%EF%BC%9A"><span class="nav-number">1.0.2.0.1.3.</span> <span class="nav-text">实验代码：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%EF%BC%9A"><span class="nav-number">1.0.2.0.1.4.</span> <span class="nav-text">实验结果：</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AlexNet"><span class="nav-number">1.0.2.0.2.</span> <span class="nav-text">AlexNet</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%EF%BC%9A-1"><span class="nav-number">1.0.2.0.2.1.</span> <span class="nav-text">模型结构：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E4%BB%A3%E7%A0%81%EF%BC%9A-1"><span class="nav-number">1.0.2.0.2.2.</span> <span class="nav-text">实验代码：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%EF%BC%9A-1"><span class="nav-number">1.0.2.0.2.3.</span> <span class="nav-text">实验结果：</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#VGGNet"><span class="nav-number">1.0.2.0.3.</span> <span class="nav-text">VGGNet</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%EF%BC%9A-2"><span class="nav-number">1.0.2.0.3.1.</span> <span class="nav-text">模型结构：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E4%BB%A3%E7%A0%81%EF%BC%9A-2"><span class="nav-number">1.0.2.0.3.2.</span> <span class="nav-text">实验代码：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%EF%BC%9A-2"><span class="nav-number">1.0.2.0.3.3.</span> <span class="nav-text">实验结果：</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="屈少"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">屈少</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3F1LXNoYW8=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qu-shao"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS91c2Vycy8xODY3NTcxNC9xdXNoYW8=" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;18675714&#x2F;qushao"><i class="fab fa-stack-overflow fa-fw"></i>StackOverflow</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vODc5NzkwMQ==" title="Bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;8797901"><i class="fa-brands fa-bilibili fa-fw"></i>Bilibili</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly93ZWliby5jb20vdS82MDgzNTEyMzI2" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;6083512326"><i class="fab fa-weibo fa-fw"></i>Weibo</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnF1ZGV5aW5nQGdtYWlsLmNvbQ==" title="E-Mail → mailto:qudeying@gmail.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://qushao.top/2022/04831f11ff.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="屈少">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="屈少">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="CNN（卷积神经网络）学习笔记 | 屈少">
      <meta itemprop="description" content="CNN(卷积神经网络)学习笔记，包括卷积神经网络的基础以及CNN典型网络的实现">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CNN（卷积神经网络）学习笔记
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-04-10 22:00:00" itemprop="dateCreated datePublished" datetime="2022-04-10T22:00:00+08:00">2022-04-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
    <span id="/2022/04831f11ff.html" class="post-meta-item leancloud_visitors" data-flag-title="CNN（卷积神经网络）学习笔记" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Changyan: </span>
    
    <a title="CNN（卷积神经网络）学习笔记" href="/2022/04831f11ff.html#SOHUCS" itemprop="discussionUrl">
      <span id="sourceId::40ef519c7ea0784af325a7bfe38b37eb" class="cy_cmt_count" itemprop="commentCount"></span>
    </a>
  </span>
  
  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2022/04831f11ff.html#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2022/04831f11ff.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

            <div class="post-description">CNN(卷积神经网络)学习笔记，包括卷积神经网络的基础以及CNN典型网络的实现</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="CNN- 卷积神经网络 - 学习笔记"><a href="#CNN- 卷积神经网络 - 学习笔记" class="headerlink" title="CNN(卷积神经网络)学习笔记"></a>CNN(卷积神经网络)学习笔记</h1><hr>
<h3 id="基本概念"><a href="# 基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p><img data-src="/images/CNN.png"></p>
<p>&emsp;&emsp; 神经网络的基本组成为输入层、隐藏层和输出层。而卷积神经网络和一般的神经网络的区别在于将隐藏层细分为了卷积层、池化层和激活层，其中卷积层通过卷积核在原始图像上平移提取特征；池化层（一般为最大池化和平均池化）压缩数据和参数的量，减小过拟合，降低网路的复杂程度；激活层用来增加非线性分割的能力。</p>
<p>&emsp;&emsp; 为什么需要卷积神经网络：图片数据由很多的像素点组成，每个像素点在不同通道（一般为 RGB，3 种通道）的值共同表征一张图片。因此一般来说，一张图片数据的输入为 N*N*C（其中 N*N 为图片的像素点个数，C 为通道数），而在现实中，N 一般可以达到上千，对于一般的神经网络，假设一层隐藏层的神经元个数为 M，对于该层隐藏层，需要的参数个数为 N*N*M，这会导致神经网络的参数过多了。我们知道，神经网络的学习能力一般是与神经网络的参数个数正相关的，过多的参数会导致最终模型的学习能力过强，过拟合，同时，过多的参数也会增加计算的复杂度。</p>
<p>&emsp;&emsp; 而卷积神经网络可以大大减少神经网络所需要的参数。卷积神经网络的核心就是卷积核，而卷积核的本质就是一个大小很小的矩阵（三维输入的神经元，长度 * 宽度 * 通道），我们通过将这个矩阵在图像上平移运算提取图像的某种特征。卷积核不同，提取的特征也就不同。</p>
<p>&emsp;&emsp; 对于卷积核，我们必须明确，卷积核的深度应该和输入数据的深度一致（比如 3 通道的图像，则处理的卷积核深度也为 3，因为这一特性，在使用一些 api 的时候不需要人工地指定该值），其次，卷积核的数量等价于经卷积核运算输出的维度，池化层其实也可以看做特殊的一种卷积核，因为一般经过池化后输出数据的大小会小于输入数据的大小（通过设置步长），为保证不损失太多的信息，通常会选择在池化层增加“卷积核”的数量从而产生更多维度的数据。</p>
<h5 id="图片卷积输出大小公式："><a href="# 图片卷积输出大小公式：" class="headerlink" title="图片卷积输出大小公式："></a>图片卷积输出大小公式：</h5><p>输入图片大小——W*W</p>
<p>卷积核大小——F*F</p>
<p>步长——S</p>
<p>padding 的大小——P<br>$$<br>N&#x3D;(W-F+2<em>P)&#x2F;S+1<br>$$<br>输出图片大小为 N</em>N</p>
<p>PS: 对这些超参数，常见的设置是 F&#x3D;3，S&#x3D;1，P&#x3D;1</p>
<h5 id="卷积层参数个数计算公式："><a href="# 卷积层参数个数计算公式：" class="headerlink" title="卷积层参数个数计算公式："></a>卷积层参数个数计算公式：</h5><p>存在 bias：<br>$$<br>Count&#x3D;C_{out}*(k_{weight}*k_{height}*C_{in}+1)<br>$$</p>
<hr>
<p>&emsp;&emsp; 卷积和池化相当于做特征工程，最后的全连接层在整个卷积神经网络中起到“分类器”的作用（如果 FC 层作为最后一层，再加上 softmax 或者 wx+b，则可以分别作为分类或回归的作用，即“分类器”或“回归器”的作用）；如果作为倒数第 2，3 层的话，FC 层的作用是信息融合，增强信息表达。</p>
<hr>
<h3 id="经典案例"><a href="# 经典案例" class="headerlink" title="经典案例"></a>经典案例 </h3><h5 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h5><p>&emsp;&emsp;LeNet 神经网络由深度学习三巨头之一的 Yan LeCun 提出，他同时也是卷积神经网络 (CNN，Convolutional Neural Networks) 之父。LeNet 主要用来进行手写字符的识别与分类，并在美国的银行中投入了使用。LeNet 的实现确立了 CNN 的结构，现在神经网络中的许多内容在 LeNet 的网络结构中都能看到，例如卷积层，Pooling 层，ReLU 层。虽然 LeNet 早在 20 世纪 90 年代就已经提出了，但由于当时缺乏大规模的训练数据，计算机硬件的性能也较低，因此 LeNet 神经网络在处理复杂问题时效果并不理想。LeNet 的设计较为简单，其处理复杂数据的能力有限；此外，在近年来的研究中许多学者已经发现全连接层的计算代价过大，而使用全部由卷积层组成的神经网络。</p>
<h6 id="模型结构："><a href="# 模型结构：" class="headerlink" title="模型结构："></a>模型结构：</h6><p><img data-src="/images/LeNet.jpeg"></p>
<p>&emsp;&emsp;LeNet-5 包含七层，不包括输入，每一层都包含可训练参数（权重)，当时使用的输入数据是 32*32 像素的图像。下面逐层介绍 LeNet-5 的结构，并且，卷积层将用 Cx 表示，子采样层则被标记为 Sx，完全连接层被标记为 Fx，其中 x 是层索引。</p>
<p>层 C1 是具有六个 5*5 的卷积核的卷积层（convolution），特征映射的大小为 28*28，这样可以防止输入图像的信息掉出卷积核边界。C1 包含 156 个可训练参数和 122304 个连接。</p>
<p>层 S2 是输出 6 个大小为 14*14 的特征图的子采样层（subsampling&#x2F;pooling）。每个特征图中的每个单元连接到 C1 中的对应特征图中的 2*2 个邻域。S2 中单位的四个输入相加，然后乘以可训练系数（权重），然后加到可训练偏差（bias）。结果通过 S 形函数传递。由于 2*2 个感受域不重叠，因此 S2 中的特征图只有 C1 中的特征图的一半行数和列数。S2 层有 12 个可训练参数和 5880 个连接。</p>
<p>层 C3 是具有 16 个 5*5 的卷积核的卷积层。前六个特征图的输入是 S2 中的三个特征图的每个连续子集，接下来的六个特征图的输入则来自四个连续子集的输入，接下来的三个特征图的输入来自不连续的四个子集。最后一个特征图的输入来自 S2 所有特征图。C3 层有 1516 个可训练参数和 151600 个连接。</p>
<p>层 S4 是与 S2 类似，大小为 2*2，输出为 16 个 5*5 的特征图。S4 层有 32 个可训练参数和 2000 个连接。</p>
<p>层 C5 是具有 120 个大小为 5*5 的卷积核的卷积层。每个单元连接到 S4 的所有 16 个特征图上的 5*5 邻域。这里，因为 S4 的特征图大小也是 5*5，所以 C5 的输出大小是 1*1。因此 S4 和 C5 之间是完全连接的。C5 被标记为卷积层，而不是完全连接的层，是因为如果 LeNet-5 输入变得更大而其结构保持不变，则其输出大小会大于 1*1，即不是完全连接的层了。C5 层有 48120 个可训练连接。</p>
<p>F6 层完全连接到 C5，输出 84 张特征图。它有 10164 个可训练参数。这里 84 与输出层的设计有关。</p>
<h6 id="各层参数变化："><a href="# 各层参数变化：" class="headerlink" title="各层参数变化："></a>各层参数变化：</h6><p>C1<br> 输入大小：32*32<br> 核大小：5*5<br> 核数目：6<br> 输出大小：28*28*6<br> 训练参数数目：(5*5+1)*6&#x3D;156<br> 连接数：(5*5+1)*6*(32-2-2)*(32-2-2)&#x3D;122304</p>
<p>S2<br> 输入大小：28*28*6<br> 核大小：2*2<br> 核数目：1<br> 输出大小：14*14*6<br> 训练参数数目：2*6&#x3D;12，2&#x3D;(w,b)<br> 连接数：(2*2+1)*1*14*14*6 &#x3D; 5880</p>
<p>C3<br> 输入大小：14*14*6<br> 核大小：5*5<br> 核数目：16<br> 输出大小：10*10*16<br> 训练参数数目：6*(3*5*5+1) + 6*(4*5*5+1) + 3*(4*5*5+1) + 1*(6*5*5+1)&#x3D;1516<br> 连接数：(6*(3*5*5+1) + 6*(4*5*5+1) + 3*(4*5*5+1) + 1*(6*5*5+1))*10*10&#x3D;151600</p>
<p>S4<br> 输入大小：10*10*16<br> 核大小：2*2<br> 核数目：1<br> 输出大小：5*5*16<br> 训练参数数目：2*16&#x3D;32<br> 连接数：(2*2+1)*1*5*5*16&#x3D;2000</p>
<p>C5<br> 输入大小：5*5*16<br> 核大小：5*5<br> 核数目：120<br> 输出大小：120*1*1<br> 训练参数数目：(5*5*16+1)*120*1*1&#x3D;48120（因为是全连接）<br> 连接数：(5*5*16+1)*120*1*1&#x3D;48120</p>
<p>F6<br> 输入大小：120<br> 输出大小：84<br> 训练参数数目：(120+1)*84&#x3D;10164<br> 连接数：(120+1)*84&#x3D;10164</p>
<h6 id="实验代码："><a href="# 实验代码：" class="headerlink" title="实验代码："></a>实验代码：</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据</span></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line"><span class="comment"># 将图片从 28*28 扩展成 32*32</span></span><br><span class="line">X_train = np.pad(x_train, ((<span class="number">0</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>)), <span class="string">&#x27;constant&#x27;</span>, constant_values=<span class="number">0</span>)</span><br><span class="line">X_test = np.pad(x_test, ((<span class="number">0</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>)), <span class="string">&#x27;constant&#x27;</span>, constant_values=<span class="number">0</span>)</span><br><span class="line">X_train = X_train.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">X_test = X_test.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"><span class="comment"># 数据正则化</span></span><br><span class="line">X_train /= <span class="number">255</span></span><br><span class="line">X_test /= <span class="number">255</span></span><br><span class="line"><span class="comment"># 数据维度转换</span></span><br><span class="line">X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">32</span>, <span class="number">32</span>, <span class="number">1</span>)</span><br><span class="line">X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">32</span>, <span class="number">32</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential()</span><br><span class="line"><span class="comment"># 卷积层，6 个 5x5 卷积核，步长为 1，relu 激活，第一层需指定 input_shape</span></span><br><span class="line">model.add(tf.keras.layers.Conv2D(filters=<span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                 activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">1</span>)))</span><br><span class="line"><span class="comment"># 平均池化，池化窗口默认为 2</span></span><br><span class="line">model.add(tf.keras.layers.AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"><span class="comment"># 卷积层，16 个 5x5 卷积核，步为 1，relu 激活</span></span><br><span class="line">model.add(tf.keras.layers.Conv2D(filters=<span class="number">16</span>, kernel_size=(</span><br><span class="line">    <span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># 平均池化，池化窗口默认为 2</span></span><br><span class="line">model.add(tf.keras.layers.AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"><span class="comment"># 需展平后才能与全连接层相连</span></span><br><span class="line">model.add(tf.keras.layers.Flatten())</span><br><span class="line"><span class="comment"># 全连接层，输出为 120，relu 激活</span></span><br><span class="line">model.add(tf.keras.layers.Dense(units=<span class="number">120</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># 全连接层，输出为 84，relu 激活</span></span><br><span class="line">model.add(tf.keras.layers.Dense(units=<span class="number">84</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># 全连接层，输出为 10，Softmax 激活</span></span><br><span class="line">model.add(tf.keras.layers.Dense(units=<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"><span class="comment"># 查看网络结构</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment"># 超参数设置</span></span><br><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line">adam_optimizer = tf.keras.optimizers.Adam(learning_rate)</span><br><span class="line"><span class="comment"># 编译</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=adam_optimizer,</span><br><span class="line">              loss=tf.keras.losses.sparse_categorical_crossentropy,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">training = model.fit(x=X_train,</span><br><span class="line">                     y=y_train,</span><br><span class="line">                     batch_size=batch_size,</span><br><span class="line">                     epochs=num_epochs,</span><br><span class="line">                     validation_split=<span class="number">0.20</span>)</span><br><span class="line"><span class="built_in">print</span>(model.evaluate(X_test, y_test))</span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save(<span class="string">&quot;LeNet_model&quot;</span>, save_format=<span class="string">&quot;tf&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练过程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_process</span>(<span class="params">training, train, validation</span>):</span><br><span class="line">    plt.plot(training.history[train], linestyle=<span class="string">&quot;-&quot;</span>, color=<span class="string">&quot;b&quot;</span>)</span><br><span class="line">    plt.plot(training.history[validation], linestyle=<span class="string">&quot;--&quot;</span>, color=<span class="string">&quot;r&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;training_history&quot;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">    plt.ylabel(train)</span><br><span class="line">    plt.legend([<span class="string">&quot;train&quot;</span>, <span class="string">&quot;validation&quot;</span>], loc=<span class="string">&quot;lower right&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_process(training, <span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;val_accuracy&quot;</span>)</span><br><span class="line">show_process(training, <span class="string">&quot;loss&quot;</span>, <span class="string">&quot;val_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型</span></span><br><span class="line">predict_x = model.predict(X_test)</span><br><span class="line">prediction = np.argmax(predict_x, axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    index = np.random.randint(<span class="number">0</span>, <span class="number">10000</span>)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">4</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.imshow(x_test[index], cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;y=&quot;</span> + <span class="built_in">str</span>(y_test[index]) + <span class="string">&quot;\ny_pred=&quot;</span> + <span class="built_in">str</span>(prediction[index]))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h6 id="实验结果："><a href="# 实验结果：" class="headerlink" title="实验结果："></a>实验结果：</h6><p><img data-src="/images/LeNet_acc.png"></p>
<p><img data-src="/images/LeNet_loss.png"></p>
<p><img data-src="/images/LeNet_res.png"></p>
<hr>
<h5 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h5><p>&emsp;&emsp;AlexNet 由 Geoffrey 和他的学生 Alex 提出，并在 2012 年的 ILSVRC 竞赛中获得了第一名。Alexnet 共有 8 层结构，前 5 层为卷积层，后三层为全连接层。AlexNet 网络结构具有如下特点：</p>
<ol>
<li>AlexNet 在激活函数上选取了非线性非饱和的 relu 函数，在训练阶段梯度衰减快慢方面，relu 函数比传统神经网络所选取的非线性饱和函数（如 sigmoid 函数，tanh 函数）要快许多。</li>
<li>AlexNet 在双 gpu 上运行，每个 gpu 负责一半网络的运算。</li>
<li>采用局部响应归一化（LRN）。对于非饱和函数 relu 来说，不需要对其输入进行标准化，但 Alex 等人发现，在 relu 层加入 LRN，可形成某种形式的横向抑制，从而提高网络的泛华能力。</li>
<li>池化方式采用 overlapping pooling。即池化窗口的大小大于步长，使得每次池化都有重叠的部分。（ps: 这种重叠的池化方式比传统无重叠的池化方式有着更好的效果，且可以避免过拟合现象的发生）</li>
<li>使用随机丢弃技术（dropout）选择性地忽略训练中的单个神经元，避免模型的过拟合。</li>
</ol>
<h6 id="模型结构：-1"><a href="# 模型结构：-1" class="headerlink" title="模型结构："></a>模型结构：</h6><p><img data-src="/images/AlexNet.png"></p>
<p>&emsp;&emsp;AlexNet 一共有 8 层</p>
<p>第一层：卷积层 1，输入为 224 × 224 × 3 的图像，卷积核的数量为 96，论文中两片 GPU 分别计算 48 个核; 卷积核的大小为 11 × 11 × 3，stride &#x3D; 4，padding &#x3D; 2。然后进行 (Local Response Normalized), 后面跟着池化 pool_size &#x3D; (3, 3), stride &#x3D; 2, padding &#x3D; 0 最终获得第一层卷积的 feature map，最终第一层卷积的输出为 96×55×55；</p>
<p>第二层：卷积层 2，输入为上一层卷积的 feature map， 卷积核的个数为 256 个，论文中的两个 GPU 分别有 128 个卷积核。卷积核的大小为：5 × 5 × 48, padding &#x3D; 2, stride &#x3D; 1; 然后做 LRN， 最后 max_pooling, pool_size &#x3D; (3, 3), stride &#x3D; 2；</p>
<p>第三层：卷积层 3，输入为第二层的输出，卷积核个数为 384, kernel_size &#x3D; (3 × 3 × 256)， padding &#x3D; 1，第三层没有做 LRN 和 Pool；</p>
<p>第四层：卷积层 4，输入为第三层的输出，卷积核个数为 384, kernel_size &#x3D; (3 × 3), padding &#x3D; 1，和第三层一样，没有 LRN 和 Pool；</p>
<p>第五层：卷积层 5，输入为第四层的输出，卷积核个数为 256, kernel_size &#x3D; (3 × 3), padding &#x3D; 1。然后直接进行 max_pooling, pool_size &#x3D; (3, 3), stride &#x3D; 2；</p>
<p>第 6，7，8 层是全连接层，每一层的神经元的个数为 4096，最终输出 softmax 为 1000（ImageNet 这个比赛的分类个数为 1000）。全连接层中使用了 RELU 和 Dropout。</p>
<h6 id="实验代码：-1"><a href="# 实验代码：-1" class="headerlink" title="实验代码："></a>实验代码：</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class="string">&#x27;True&#x27;</span></span><br><span class="line">(X_train, Y_train), (X_test, Y_test) = mnist.load_data()</span><br><span class="line">X_test1 = X_test</span><br><span class="line">Y_test1 = Y_test</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理图像特征 </span></span><br><span class="line">X_train = X_train.reshape(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">&quot;float32&quot;</span>) / <span class="number">255.0</span></span><br><span class="line">X_test = X_test.reshape(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">&quot;float32&quot;</span>) / <span class="number">255.0</span></span><br><span class="line"><span class="comment"># 处理标签</span></span><br><span class="line">Y_train = np_utils.to_categorical(Y_train, <span class="number">10</span>)</span><br><span class="line">Y_test = np_utils.to_categorical(Y_test, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建 AlexNet 网络模型</span></span><br><span class="line"><span class="comment"># 建立第一层卷积</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(</span><br><span class="line">    filters=<span class="number">96</span>,</span><br><span class="line">    kernel_size=(<span class="number">11</span>, <span class="number">11</span>),</span><br><span class="line">    strides=<span class="number">4</span>,</span><br><span class="line">    padding=<span class="string">&quot;same&quot;</span>,</span><br><span class="line">    input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>),</span><br><span class="line">    activation=<span class="string">&quot;relu&quot;</span></span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建 BN 层</span></span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line"><span class="comment"># 搭建第一层重叠最大池化层</span></span><br><span class="line">model.add(MaxPool2D(</span><br><span class="line">    pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">    strides=<span class="number">2</span>,</span><br><span class="line">    padding=<span class="string">&quot;same&quot;</span></span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立第二层卷积</span></span><br><span class="line">model.add(Conv2D(</span><br><span class="line">    filters=<span class="number">256</span>,</span><br><span class="line">    kernel_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">    strides=<span class="number">1</span>,</span><br><span class="line">    padding=<span class="string">&quot;same&quot;</span>,</span><br><span class="line">    activation=<span class="string">&quot;relu&quot;</span></span><br><span class="line">))</span><br><span class="line"><span class="comment"># 搭建 BN 层</span></span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line"><span class="comment"># 搭建第二层池化层</span></span><br><span class="line">model.add(MaxPool2D(</span><br><span class="line">    pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">    strides=<span class="number">2</span>,</span><br><span class="line">    padding=<span class="string">&quot;same&quot;</span>,</span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建第三层卷积</span></span><br><span class="line">model.add(Conv2D(</span><br><span class="line">    filters=<span class="number">384</span>,</span><br><span class="line">    kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">    strides=<span class="number">1</span>,</span><br><span class="line">    padding=<span class="string">&quot;same&quot;</span>,</span><br><span class="line">    activation=<span class="string">&quot;relu&quot;</span>,</span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建第四层卷积</span></span><br><span class="line">model.add(Conv2D(</span><br><span class="line">    filters=<span class="number">384</span>,</span><br><span class="line">    kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">    strides=<span class="number">1</span>,</span><br><span class="line">    padding=<span class="string">&quot;same&quot;</span>,</span><br><span class="line">    activation=<span class="string">&quot;relu&quot;</span></span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建第五卷积层</span></span><br><span class="line">model.add(Conv2D(</span><br><span class="line">    filters=<span class="number">256</span>,</span><br><span class="line">    kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">    strides=<span class="number">1</span>,</span><br><span class="line">    padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">    activation=<span class="string">&quot;relu&quot;</span></span><br><span class="line">))</span><br><span class="line">model.add(MaxPool2D(</span><br><span class="line">    pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">    strides=<span class="number">2</span>,</span><br><span class="line">    padding=<span class="string">&quot;same&quot;</span></span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建第六层：全连接层</span></span><br><span class="line"><span class="comment"># 在搭建全连接层之前，必须使用 Flatten() 降维</span></span><br><span class="line">model.add(Flatten())</span><br><span class="line"><span class="comment"># 全连接层</span></span><br><span class="line">model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line"><span class="comment"># 搭建第七层：全连接层</span></span><br><span class="line">model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line"><span class="comment"># 搭建第八层：全连接层即输出层</span></span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>))</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译</span></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    loss=<span class="string">&quot;categorical_crossentropy&quot;</span>,</span><br><span class="line">    optimizer=<span class="string">&quot;adam&quot;</span>,</span><br><span class="line">    metrics=[<span class="string">&quot;accuracy&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">n_epoch = <span class="number">10</span></span><br><span class="line">n_batch = <span class="number">256</span></span><br><span class="line">training = model.fit(</span><br><span class="line">    X_train,</span><br><span class="line">    Y_train,</span><br><span class="line">    epochs=n_epoch,</span><br><span class="line">    batch_size=n_batch,</span><br><span class="line">    verbose=<span class="number">1</span>,</span><br><span class="line">    validation_split=<span class="number">0.20</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 评估</span></span><br><span class="line"><span class="built_in">print</span>(model.evaluate(X_train, Y_train, verbose=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save(<span class="string">&quot;AlexNet_model&quot;</span>, save_format=<span class="string">&quot;tf&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练过程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_process</span>(<span class="params">training, train, validation</span>):</span><br><span class="line">    plt.plot(training.history[train], linestyle=<span class="string">&quot;-&quot;</span>, color=<span class="string">&quot;b&quot;</span>)</span><br><span class="line">    plt.plot(training.history[validation], linestyle=<span class="string">&quot;--&quot;</span>, color=<span class="string">&quot;r&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;training_history&quot;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">    plt.ylabel(train)</span><br><span class="line">    plt.legend([<span class="string">&quot;train&quot;</span>, <span class="string">&quot;validation&quot;</span>], loc=<span class="string">&quot;lower right&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_process(training, <span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;val_accuracy&quot;</span>)</span><br><span class="line">show_process(training, <span class="string">&quot;loss&quot;</span>, <span class="string">&quot;val_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">predict_x = model.predict(X_test)</span><br><span class="line">prediction = np.argmax(predict_x, axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    index = np.random.randint(<span class="number">0</span>, <span class="number">10000</span>)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.imshow(X_test1[index])</span><br><span class="line">    plt.title(<span class="string">&quot;y=&quot;</span> + <span class="built_in">str</span>(Y_test1[index]) + <span class="string">&quot;\ny_pred=&quot;</span> + <span class="built_in">str</span>(prediction[index]))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h6 id="实验结果：-1"><a href="# 实验结果：-1" class="headerlink" title="实验结果："></a>实验结果：</h6><p><img data-src="/images/AlexNet_acc.png"></p>
<p><img data-src="/images/AlexNet_loss.png"></p>
<p><img data-src="/images/AlexNet_res.png"></p>
<hr>
<h5 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h5><p>&emsp;&emsp;2014 年，牛津大学计算机视觉组和 Google DeepMind 公司的研究员一起研发出了新的深度卷积神经网络：VGGNet，并取得了 ILSVRC2014 比赛分类项目的第二名（第一名是 GoogLeNet，也是同年提出的）和定位项目的第一名。</p>
<p>&emsp;&emsp;VGGNet 探索了卷积神经网络的深度与其性能之间的关系，成功地构筑了 16~19 层深的卷积神经网络，证明了增加网络的深度能够在一定程度上影响网络最终的性能，使错误率大幅下降，同时拓展性又很强，迁移到其它图片数据上的泛化性也非常好。到目前为止，VGG 仍然被用来提取图像特征。VGGNet 可以看成是加深版本的 AlexNet，都是由卷积层、全连接层两大部分构成。它有如下几个特点：</p>
<ol>
<li>小卷积核和多卷积子层，使用小卷积核 (3x3) 和多卷积子层代替一个卷积核较大的卷积层的好处一是可以减少参数，二是相当于进行了更多的非线性映射，可以增加网络的拟合 &#x2F; 表达能力。VGG 的作者认为两个 3x3 的卷积堆叠获得的感受野大小，相当一个 5x5 的卷积；而 3 个 3x3 卷积的堆叠获取到的感受野相当于一个 7x7 的卷积。这样可以增加非线性映射，也能很好地减少参数（例如 7x7 的参数为 49 个，而 3 个 3x3 的参数为 27）</li>
<li>小池化核，相比 AlexNet 的 3x3 的池化核，VGG 全部采用 2x2 的池化核。</li>
<li>通道数多，VGG 网络第一层的通道数为 64，后面每层都进行了翻倍，最多到 512 个通道，通道数的增加，使得更多的信息可以被提取出来。</li>
<li>层数更深、特征图更宽，由于卷积核专注于扩大通道数、池化专注于缩小宽和高，使得模型架构上更深更宽的同时，控制了计算量的增加规模。</li>
<li>全连接转卷积（测试阶段），在网络测试阶段将训练阶段的三个全连接替换为三个卷积，使得测试得到的全卷积网络因为没有全连接的限制，因而可以接收任意宽或高为的输入，这在测试阶段很重要。</li>
<li>用简单模型初始化复杂模型，VGGNet 在训练的时候先训级别 A 的简单模型，再复用 A 网络的权重来初始化后面的几个复杂模型，这样收敛速度更快。</li>
<li>采用了 Multi-Scale 的方法来训练和预测，可以增加训练的数据量，防止模型过拟合，提升预测准确率。</li>
</ol>
<h6 id="模型结构：-2"><a href="# 模型结构：-2" class="headerlink" title="模型结构："></a>模型结构：</h6><p><img data-src="/images/VGGNet.png"></p>
<p>&emsp;&emsp;VGG16 处理过程如下：</p>
<ol>
<li>输入 224x224x3 的图片，经 64 个 3x3 的卷积核做两次卷积 +ReLU，卷积后的尺寸变为 224x224x64</li>
<li>做 max pooling（最大化池化），池化单元尺寸为 2x2（效果为图像尺寸减半），池化后的尺寸变为 112x112x64</li>
<li>经 128 个 3x3 的卷积核做两次卷积 +ReLU，尺寸变为 112x112x128</li>
<li>做 2x2 的 max pooling 池化，尺寸变为 56x56x128</li>
<li>经 256 个 3x3 的卷积核做三次卷积 +ReLU，尺寸变为 56x56x256</li>
<li>做 2x2 的 max pooling 池化，尺寸变为 28x28x256</li>
<li>经 512 个 3x3 的卷积核做三次卷积 +ReLU，尺寸变为 28x28x512</li>
<li>做 2x2 的 max pooling 池化，尺寸变为 14x14x512</li>
<li>经 512 个 3x3 的卷积核做三次卷积 +ReLU，尺寸变为 14x14x512</li>
<li>做 2x2 的 max pooling 池化，尺寸变为 7x7x512</li>
<li>与两层 1x1x4096，一层 1x1x1000 进行全连接 +ReLU（共三层）</li>
<li>通过 softmax 输出 1000 个预测结果</li>
</ol>
<h6 id="实验代码：-2"><a href="# 实验代码：-2" class="headerlink" title="实验代码："></a>实验代码：</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class="string">&quot;True&quot;</span></span><br><span class="line"><span class="comment"># 获取所有 GPU 组成 list</span></span><br><span class="line">gpus = tf.config.experimental.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br><span class="line"><span class="comment"># 设置按需申请</span></span><br><span class="line"><span class="comment"># 由于我这里仅有一块 GPU,multi-GPU 需要 for 一下</span></span><br><span class="line">tf.config.experimental.set_memory_growth(gpus[<span class="number">0</span>], <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()</span><br><span class="line">X_test1 = X_test</span><br><span class="line">Y_test1 = Y_test</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理图像特征</span></span><br><span class="line">X_train = X_train.reshape(-<span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>).astype(<span class="string">&quot;float32&quot;</span>) / <span class="number">255.0</span></span><br><span class="line">X_test = X_test.reshape(-<span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>).astype(<span class="string">&quot;float32&quot;</span>) / <span class="number">255.0</span></span><br><span class="line"><span class="comment"># 处理标签</span></span><br><span class="line">Y_train = np_utils.to_categorical(Y_train, <span class="number">10</span>)</span><br><span class="line">Y_test = np_utils.to_categorical(Y_test, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>))</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&quot;categorical_crossentropy&quot;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">log_dir = <span class="string">&quot;logs/fit/&quot;</span> + datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line">tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=<span class="number">1</span>)</span><br><span class="line">n_epoch = <span class="number">1000</span></span><br><span class="line">n_batch = <span class="number">512</span></span><br><span class="line">training = model.fit(</span><br><span class="line">    X_train,</span><br><span class="line">    Y_train,</span><br><span class="line">    epochs=n_epoch,</span><br><span class="line">    batch_size=n_batch,</span><br><span class="line">    verbose=<span class="number">1</span>,</span><br><span class="line">    validation_split=<span class="number">0.20</span>,</span><br><span class="line">    callbacks=[tensorboard_callback]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(model.evaluate(X_test, Y_test))</span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save(<span class="string">&quot;VGGNet16_model&quot;</span>, save_format=<span class="string">&quot;tf&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练过程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_process</span>(<span class="params">training, train, validation</span>):</span><br><span class="line">    plt.plot(training.history[train], linestyle=<span class="string">&quot;-&quot;</span>, color=<span class="string">&quot;b&quot;</span>)</span><br><span class="line">    plt.plot(training.history[validation], linestyle=<span class="string">&quot;--&quot;</span>, color=<span class="string">&quot;r&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;training_history&quot;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">    plt.ylabel(train)</span><br><span class="line">    plt.legend([<span class="string">&quot;train&quot;</span>, <span class="string">&quot;validation&quot;</span>], loc=<span class="string">&quot;lower right&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_process(training, <span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;val_accuracy&quot;</span>)</span><br><span class="line">show_process(training, <span class="string">&quot;loss&quot;</span>, <span class="string">&quot;val_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">class_names = [<span class="string">&#x27;airplane&#x27;</span>, <span class="string">&#x27;automobile&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>]</span><br><span class="line">predict_x = model.predict(X_test)</span><br><span class="line">prediction = np.argmax(predict_x, axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    index = np.random.randint(<span class="number">0</span>, <span class="number">10000</span>)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">4</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.imshow(X_test1[index])</span><br><span class="line">    plt.title(<span class="string">&quot;y=&quot;</span> + <span class="built_in">str</span>(class_names[<span class="built_in">int</span>(Y_test1[index])]) + <span class="string">&quot;\ny_pred=&quot;</span> + <span class="built_in">str</span>(class_names[prediction[index]]))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h6 id="实验结果：-2"><a href="# 实验结果：-2" class="headerlink" title="实验结果："></a>实验结果：</h6><p><img data-src="/images/VGGNet16_acc.png"></p>
<p><img data-src="/images/VGGNet16_loss.png"></p>
<p><img data-src="/images/VGGNet16_res.png"></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="followme">
  <span>Welcome to my other publishing channels</span>

  <div class="social-list">

      <div class="social-item">
          <span class="social-link">
            <span class="icon">
              <i class="fab fa-weixin"></i>
            </span>

            <span class="label">WeChat</span>
          </span>

          <img class="social-item-img" src="/images/Wechat.jpg">
      </div>

      <div class="social-item">
          <span class="social-link">
            <span class="icon">
              <i class="fab fa-qq"></i>
            </span>

            <span class="label">QQ</span>
          </span>

          <img class="social-item-img" src="/images/QQ.jpg">
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
              <a href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag"><i class="fa fa-tag"></i> 读书笔记</a>
              <a href="/tags/CNN/" rel="tag"><i class="fa fa-tag"></i> CNN</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/04507f527d.html" rel="prev" title="Tensorflow2.x 深度学习使用 Sequential 一般步骤">
                  <i class="fa fa-angle-left"></i> Tensorflow2.x 深度学习使用 Sequential 一般步骤
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/06f12cbde5.html" rel="next" title="MySQL 学习笔记">
                  MySQL 学习笔记 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      <div class="comment-button-group">
          <a class="btn comment-button changyan">changyan</a>
          <a class="btn comment-button disqus">disqus</a>
          <a class="btn comment-button livere">livere</a>
      </div>
        <div class="comment-position changyan">
          <div class="comments" id="SOHUCS" sid="40ef519c7ea0784af325a7bfe38b37eb"></div>
        </div>
        <div class="comment-position disqus">
          
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
        </div>
        <div class="comment-position livere">
          <div class="comments" id="lv-container" data-id="city" data-uid="MTAyMC81NTkzNC8zMjM5Nw=="></div>
        </div><script data-pjax src="/js/comments-buttons.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2021 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">屈少</span>
  </div>
  <div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9waXNjZXMv">NexT.Pisces</span>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL3F1LXNoYW8=" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.1/dist/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"prOvWcS4rkfwgccsWDsmEFKa-MdYXbMMI","app_key":"gyYtgEazqfE9MKoRgYacvBBa","server_url":"https://provwcs4.api.lncldglobal.com","security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/quicklink@2.3.0/dist/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"http://qushao.top/2022/04831f11ff.html"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<script class="next-config" data-name="changyan" type="application/json">{"enable":true,"appid":"cyw0fr0eC","appkey":"647f57b2988dfca28bf31b925114005b","count":true}</script>
<script src="/js/third-party/comments/changyan.js"></script>
<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"qushao","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>
<script src="/js/third-party/comments/livere.js"></script>

</body>
</html>
